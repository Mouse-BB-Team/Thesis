\input{chapters/implementation}
\section{Data serialization}\label{sec:data-serialization}
The persisted data from the database were to serve as the input for a machine learning model, however, due to inconvenient usage of SQL queries for such purposes, the serialization tool was developed in order to translate the state of the database records to binary files.
In the presented solution, such files were treated as immutable, so the operation of serialization could have been performed only once, which resulted in the improvement of the required time to read the data by the machine learning model.
Moreover, binary files allowed straightforward sending and storing data in external infrastructures, such as PLGrid\footnote{\url{http://www.plgrid.pl/}}, because it did not require maintenance of database engine in that environment.
Such an approach made it also possible to process data and prepare them in a way that was being required by the machine learning model.

To fulfill these requirements, the serializer and deserializer tools were developed for saving sequences in binary files and further reading those data in Python script.
The serialization was being performed using a tool written in Go\footnote{\url{https://golang.org/}} and provided additional tuning of resulted binary files and configuration of connection to the database.
Among the others the tool allowed to choose the type of event generated by the user such as mouse click or move, minimum sequence length that should have been considered as valid data, minimum screen resolution in order to filter the actions from mobile devices or the time gap between two actions that should have been considered as the boundary between two sequences.
The results of such filtration were being saved in the chosen directory dividing the output into the user's directories and saving each separate sequence in a single file, so the output consisted of many user's directories each containing many single sequence files.
It was possible to use also a so-called one-user mode that enabled generating output data only for a single arbitrary chosen user for debugging purposes.

In order to make serialization uncomplicated and transferable between different programming languages, the serialization framework was used.
At the beginning the chosen one was Apache Avro\footnote{\url{https://avro.apache.org/}} which allows to defining the schema in simple JSON file.
The serialization is performed with help of a library that allows reading schema and saving programming language native objects to binary files.
In the presented solution serialization should have been performed using the library for Go and the deserialization with support of the library for Python, however, they proved to be incompatible which resulted in errors in deserialized data.

To avoid invalid data and to do not spend too much time on finding the bug in those libraries, another approach was taken by applying the Protocol Buffers\footnote{\url{https://developers.google.com/protocol-buffers}} technology.
Protocol Buffers or simply Protobuf is a method of serializing data to the binary form, but the real advantage of it is official multilingual support by generating a serializing code in required programming language.
Protobuf also requires the definition of a schema like Apache Avro, but unlike Avro, the config file format is developed especially for Protobuf, at the same time it is also readable and effortless to write.
Basing on the created schema the code was generated both for Serializer and Deserializer, but in the case of Deserializer, the data was directly read to the Pandas\footnote{\url{https://pandas.pydata.org/}} Dataframe objects, which provided a simple interface to manipulate huge amount of data.
