\subsection{Model execution strategy}\label{subsec:model-execution-strategy}
As stated before, the model is running several times.
To save time and optimize resources usage, the first approach for running the model was to execute it in a multi-threaded way.
For this purpose, the module which was facilitating that was created.
Soon this approach was abandoned due to the encountered problems.

When run on the Prometheus cluster, the better approach was to split the computation between two GPUs and run the model sequentially.
For this purpose, the Mirrored Strategy distribution technique from the TensorFlow library was used whereas training is split across multiple replicas.
Thanks to the split and the computing power of GPU, single execution is fast, thus can be multiplied several times.
