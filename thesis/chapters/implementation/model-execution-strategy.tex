\subsection{Model execution strategy}\label{subsec:model-execution-strategy}
As stated before, the model is running several times.
To save time and optimize resources usage, the first approach for running the model was to execute it in a multi-threaded way.
For this purpose, the module which was facilitating that was created.
Soon this approach was abandoned due to the encountered problems.
The main problem was that the SLURM manager is not able to split the resources in a way to the multithreaded approach to be sensible.
The resources were assigned to the whole computing node on which only 2 \gls{gpu} cards were able to be allocated.
This caused the problem of many machine learning models trying to run on a single card.

When run on the Prometheus cluster, the better approach was to split the computation between two \gls{gpu}s and run the model sequentially.
For this purpose, the Mirrored Strategy distribution technique from the TensorFlow library was used whereas training is split across multiple replicas.
Thanks to the split and the computing power of \gls{gpu}, single execution is fast, thus can be multiplied several times.
